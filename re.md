1. 传统目标检测算法
传统的目标检测算法可以分为两个方向：根据特征进行目标识别、根据分割进行目标识别。在传统的算法中，主要的特征有Harr特征[3]、HOG特征[4]、SIFT特征等。人为提取特征的效果难以保证是传统目标检测算法的一大缺点，可移植性较差，时间复杂度高，存在大量的冗余计算，势必会导致运行速度难以提升，而且面对复杂多变的环境时，鲁棒性差，只有在一些特定的环境下才会有较好的表现，因此现实生活中也得不到大规模的使用。在计算机视觉技术迅猛发展的今天，基于深度学习的目标检测算法因实时精度高，逐步替代了传统目标检测方法。在复杂场景下，背景变化剧烈时，传统的目标检测算法会出现误检或漏检等现象。为克服传统目标检测算法准确性不高的不足，提出一种两阶段目标检测算法。
2. 基于深度学习的两阶段目标检测算法
2013年Sermanet等人[5]提出了著名的OverFeat算法。OverFeat可以说是单阶段目标检测算法的经典开山之作，基于AlexNet[6]实现了识别、定位、检测共用同一个网络框架。这也是首篇介绍使用一个网络就能解决这一问题的方法。它利用了卷积神经网络的特征提取功能，把分类过程中提取到的特征又同时用于定位检测任务。该论文通过一种应用于回归边界框的贪婪合并策略，合并各个预测，是一种全新的定位与检测方法。整体没有全连接层，采用全卷积网络，消除了传统滑动窗口方法的很多冗余计算，提高了算法的鲁棒性又保证了效率。此算法对后续深度学习目标检测算法的发展有着重要意义。但是该算法对小目标的检测效果不理想，且存在较高错误率。2014年，R-CNN搭载着“RegionProposal（候选框）+CNN”提取的分类网络的组合模式出现在大众视野中，这种两阶段目标检测算法以其优秀的准确度给目标检测算法提供了新思路。Twostage（两阶段）目标检测算法将目标检测分为两大部分：候选区域的选取、目标的分类识别。两阶段目标检测算法的优势在于选取多个候选框可以充分提取目标的特征信息，检测的准确度高，同时可以实现精准定位，但是因为算法模型复杂且分两个步骤进行，所以检测速度较慢。下面简要介绍一些经典的两阶段检测算法以及它们的优缺点。
2.1 R-CNN
R-CNN[7]算法由Girshick等人在2014年提出，它开启了将深度学习运用在目标检测的大门，并为后续该系列检测算法奠定了基础。此后，目标检测算法的实时性与精确度不断提高。R-C N N目标检测算法可分为四个
步骤：第一步，利用选择性搜索算法SS（Selective Search） [8]从图像中提取约2000个候选框。第二步，利用深度卷积神经网络提取各候选框的函数向量。第三步，用AlexNet将各个函数向量发送给各个向量机（S V M），判断是否属于此类。第四步，使用边界框的回归和非极大值抑制算法来获得候选的最佳框。虽然该算法大幅提高了平均精确度，但是因为需要对2000个候选框进行特征提取，所以检测速度较慢。针对此问题，H e等人在2015年提出了SPP-Net[9]算法。
2.2 SPP-Net
因为R-CNN算法只能对固定大小的图像进行卷积运算，这就会导致特征信息损失和运算速度慢的问题出现。为了解决R-CNN算法提取特征操作冗长的问题，He等人在2015年提出了SPP-Net算法。SPP-Net算法同样大致分为四个步骤：第一步，采用SS（Selective Search）方法让一张图片生成2000个候选区域；第二步，利用空间金字塔池化[10]（SpatialPyramid Pooling,SPP）操作，把每个候选区域对应的特征转换成固定长度的特征；第三步，输入全连接层；第四步，进行后续SVM的分类和回归。SPP-Net算法通过引入SPP来避免重复进行卷积运算，在保证同样或者更好的检测精度的同时，极大地提升了检测速度，相比R-CNN 算法快24～102倍[11]。首先，训练还处于多个阶段，接下来，SPP-Net只对完全连接的层进行了微调，忽略了之前的所有层，添加池化层后，网络只更新下面的完整连接层，忽略了以前层数对模型的影响，从而降低了检测精
度。为了解决R-CNN和SPP网络的缺点，Girshick等人在2015年提出了Fast R-CNN算法。
2.3 Fast R-CNN
Fast R-CNN[12]是对R-CNN算法的改进，在卷积计算部分使用V G G16网络代替AlexNet网络，并且融合了SPPnet的思想，将网络的SPP层设计成为单独的一层，即ROI(Region of Interesting)P o o l i n g层，进一步解决了权值更新的问题。该算法引入SVD（Singular ValueDecomposition）对全连接层进行分解，使得处理一张图片的速度明显提升。FastR-CNN将卷积神经网络提取的特征存储在显存中，减少了对磁盘空间的占用，提高了训练性能，加快了训练速度。同时在网络中加入多任务损失函数边框回归，整个训练过程仅包括候选区域提取和CNN训练两个阶段。但是，该算法存在一些缺陷。它仍然使用SS (Selective
Search)方法来选择候选区域，这一步仍然会有大量的计算。Fast R-CNN虽然成功地融合了R-CNN和SPP-Net的优点，但仍然无法实现端到端的目标检测。例如，不能同时获得候选区域，速度仍有提高的空间。
2.4 Faster R-CNN
针对以上网络存在的不足，在 FastR-CNN 之后不久，Ren等人在2015年提出了Faster R-CNN[13]算法。Faster R-CNN是第一个接近实时的深度学习检测算法。Faster R-CNN的主要贡献是引入了区域生成网络（Region Proposal Networks，RPN），代替Selective Search算法。尽管Faster R-CNN已经突破了Fast R-CNN的速度瓶颈，但是后续检测阶段仍存在计算冗余问题。它继续沿用ROI Pooling层，这就会导致降低目标检测中定位的准确性，而且Faster R-CNN对小目标的检测效果不佳，后来提出了各种改进方案，包括R-FCN[14]和Light head R-CNN[15]都对Faster R-CNN做了进一步的改进。
2.5 FPN
为了解决Faster R-CNN目标检测算法在应对多尺度变化问题时的不足，以及对小目标检测效果不佳等问题，Lin等人在Faster R-CNN的基础上提出了FPN[16]算法。文章将一种自顶向下、带有侧向连接的层次结构应用在Faster R-CNN算法中，使得算法在不增加计算量的同时，对小目标的检测能力大幅提升。在FPN出现之前，大多数基于深度学习的目标检测算法都只用顶层特征做预测，虽然深层的特征语义信息丰富，但是目标位置却很模糊。FPN通过连续上采样和跨层融合，使得输出特征既具有底层视觉信息，又具有深层语义信息。严格来说，FPN本身并不属于一种目标检测算法，它是一个骨干网络。同时它也具有一定的缺陷，因为不同层之间存在语义鸿沟，直接融合会降低多尺度表示能力，而且下采样过程会损失最高层金字塔特征信息。

3.1 R-CNN
2014年加州大学伯克利分校的Girshick 提出R-CNN算法,其在效果上超越同期的Yann Lecun提出的端到端方法——OverFeat15]算法,其算法结构也成为后续two stage 的经典结构。R-CNN算法利用选择性搜索(Selective Search)[16]算法评测相邻图像子块的特征相似度,利用合并后的相似图像区域打分,选择出感兴趣区域的候选框作为样本,并输入到卷积神经网络结构内部,由网络学习候选框和标定框组成的正负样本特征形成对应的特征向量，再由支持向量机设计分类器对特征向量进行分类,最后对候选框以及标定框完成边框回归操作，达到目标检测的定位目的。
3.2 SPP-net
2015年,何恺明等提出一种 SPP-Net 算法,通过在卷积层和全连接层之间加入空间金字塔池化结构(Spatial Pyramid Pooling)[11]代替R-CNN算法在输人卷积神经网络前对各个候选区域进行剪裁、缩放操作使其图像子块尺寸一致的做法,大大加快了产生候选框的速度,且节省了计算成本。但是与R-CNN算法一样,其训练数据的图像尺寸大小不一致,导致候选框的ROI18]感受野大,不能利用BPl19]高效更新权重。
3.3 Fast R-CNN
2015年,微软研究院的Girshick 提出一种改进的Fast R-CNN算法,其借鉴SPP-Net算法结构,通过一种ROI pooling[]的池化层结构,高效解决R-CNN算法必须将图像区域剪裁﹑缩放到相同尺寸大小的操作。但是,其仍然没有摆脱选择性搜索算法生成正负样本候选框的问题。
3.4 Faster R-CNN
2015年,微软研究院的何恺明以及Girshick 等人提出Faster R-CNN算法,同时提出RPN(RegionProposal Networks)网络,整个网络流程都能共享卷积神经网络提取的特征信息[21],节约了计算成本,且解决了Fast R-CNN算法生成正负样本候选框速度慢的问题,也能避免候选框提取过多导致算法准确率下降的问题。
3.5 Mask R-CNN
2017年,Facebook的何恺明等提出了Mask R-CNN算法。Mask R-CNN算法将ROI_Pooling 层替换成了ROI_Align[22],并且在边框识别的基础上添加分支FCN层(mask 层),用于语义Mask识别，通过RPN 网络生成目标候选框,再对每个目标候选框分类判断和边框回归,同时利用全卷积网络对每个目标候选框预测分割掩膜[23]
